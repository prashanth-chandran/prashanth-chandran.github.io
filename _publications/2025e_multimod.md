---
title: "Multimodal Conditional 3D Face Geometry Generation"
collection: publications
permalink: /publication/multimod_2025
teaser: /images/multimod_2025.png
excerpt: In this work, we present a new method for multimodal conditional 3D face geometry generation that allows user-friendly control over the output identity and expression via a number of different conditioning signals. [[Project Page]](https://studios.disneyresearch.com/2025/10/26/multimodal-conditional-3d-face-geometry-generation/)<br><br><br>
date: 2025-10-26
venue: 'Shape Modeling International'
bibtex: "
@article{Otto2025,
title = {Multimodal Conditional 3D Face Geometry Generation},
journal = {Computers & Graphics},
volume = {132},
pages = {104325},
year = {2025},
issn = {0097-8493},
author = {Christopher Otto and Prashanth Chandran and Sebastian Weiss and Markus Gross and Gaspard Zoss and Derek Bradley},
}
"
---

**Abstract**
<p>
We present a new method for multimodal conditional 3D face geometry generation that allows user-friendly control over the output identity and expression via a number of different conditioning signals. Within a single model, we demonstrate 3D faces generated from artistic sketches, portrait photos, Canny edges, FLAME face model parameters, 2D face landmarks, or text prompts. Our approach is based on a diffusion process that generates 3D geometry in a 2D parameterized UV domain. Geometry generation passes each conditioning signal through a set of cross-attention layers (IP-Adapter), one set for each user-defined conditioning signal. The result is an easy-to-use 3D face generation tool that produces topology-consistent, high-quality geometry with fine-grain user control.
</p>

[Project Page](https://studios.disneyresearch.com/2025/10/26/multimodal-conditional-3d-face-geometry-generation/)
